{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Motivation and goals](#Motivation-and-goals)\n",
    "* [Data sources and datasets](#Data-sources-and-datasets)\n",
    "* [Data wrangling](#Data-wrangling)\n",
    "    * [Getting the files](#Getting-the-files)\n",
    "    * [Arranging the food groups](#Arranging-the-food-groups)\n",
    "    * [Putting it all together](#Putting-it-all-together)\n",
    "* [Modeling](#Modeling)\n",
    "    * [Score](#Score)\n",
    "    * [Categorisation](#Categorisation)\n",
    "    * [Logistic regression](#Logistic-regression)\n",
    "    * [Some other tool](#Some-other-tool)\n",
    "    * [Other tools](#Other-tools)\n",
    "* [Discussion](#Discussion)\n",
    "    * [Summary of findings](#Summary-of-findings)\n",
    "    * [Limitations](#Limitations)\n",
    "    * [Further work](#Further-work)\n",
    "        * [Nutrients](#Nutrients)\n",
    "        * [Food production](#Food-production)\n",
    "        * [Data science tools](#Data-science-tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===== THE CODE BELOW SHOWS HOW WITHIN A GROUP THERE MAY BE DIFFERENT UNITS:\n",
    "# === All oz:\n",
    "# ALL BREAD, ALL CARCASE MEAT, ALL FISH, ALL NON-CARCASE MEAT AND MEAT PRODUCTS,\n",
    "# BISCUITS, CAKES, BUNS, CRISPBREADS; CEREALS, EXCL. BREAD,BUNS,CAKES,BISCUITS\n",
    "# FLOUR, FRESH FRUIT, FRESH GREEN VEGETABLES, OTHER FRESH VEGETABLES\n",
    "# POTATOES, SUGAR AND PRESERVES, TOTAL CHEESE\n",
    "# === Mostly oz, some floz:\n",
    "# ALL FATS, ALL OTHER FOODS, ALL PROCESSED VEGETABLES, BEVERAGES\n",
    "# FRUIT & FRUIT PRODS. NOT FRESH\n",
    "# === Assorted units:\n",
    "# All pt: LIQUID WHOLEMILK, INC SCHOOL & WELFARE; OTHER MILK & CREAM\n",
    "# SOFT DRINKS : floz\n",
    "# CONFECTIONERY : g\n",
    "# EGGS : units of \"egg\"\n",
    "# ALCOHOLIC DRINKS : mostly cl, one ml\n",
    "\n",
    "#df = df_groups\n",
    "#df = pd.merge(df, df_min_units, how='left', on='minor')\n",
    "#list_of_groups = list(df_grp_text['group_text'].sort_values())\n",
    "#for g in list_of_groups:\n",
    "#    this_group = g\n",
    "#    dfg = df[df.group_text == this_group]\n",
    "#    list_of_units = dfg['units'].tolist()\n",
    "#    first_unit = list_of_units[0]\n",
    "#    all_units_are_the_same = \"yes\"\n",
    "#    for u in list_of_units:\n",
    "#            this_unit = u\n",
    "#            if this_unit != first_unit: all_units_are_the_same = \"no\"\n",
    "#    if all_units_are_the_same == \"no\":\n",
    "#        print this_group, \"have different units:\", list_of_units\n",
    "#        #print dfg.minor_text.unique()\n",
    "#        #print dfg[['minor_text', 'units']]\n",
    "#    else:\n",
    "#        print this_group, \"are all\", this_unit\n",
    "#        #print dfg.minor_text.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===== HOW TO SELECT FOOD GROUPS AND SPECIFIC FOOD ITEMS =====\n",
    "#df = df_groups #but could be df_diary14 below!\n",
    "#df = df[df.group_text == 'ALL BREAD']\n",
    "##print df #shows that some kinds of bread where only coded until 1992, etc\n",
    "#print df.minor_text.unique()\n",
    "\n",
    "#print \"\\nwhat are the units for quantity of the different kinds of bread?\"\n",
    "#df = df_groups\n",
    "#df = pd.merge(df, df_min_units, how='left', on='minor')\n",
    "#df = df[df.group_text == 'ALL BREAD']\n",
    "#df = df[['minor_text', 'units']]\n",
    "#print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===== HOW TO SELECT FOOD GROUPS/ITEMS FROM DIARY =====\n",
    "#df = df_diary14\n",
    "#df = df[df.group_text == 'ALL BREAD']\n",
    "#print \"how many purchases of the different kinds of bread?\"\n",
    "#print pd.value_counts(df['minor_text'].values, sort=True)\n",
    "##print df[['hhno', 'minor_text']].groupby('minor_text').count()\n",
    "\n",
    "#print \"\\nhow much quantity purchased of the different kinds of bread?\"\n",
    "#print df.groupby('minor_text').quantity.sum().sort_values(ascending = False)\n",
    "\n",
    "##pd.value_counts(dfb['minor_text'].values, sort=True)\n",
    "\n",
    "##pd.crosstab(dfb.minor_text, dfb.survyear, values = dfb.quantity, aggfunc=np.sum)\n",
    "\n",
    "##dfb.minor_text.value_counts().sort_values().plot(kind='barh')\n",
    "###pd.value_counts(dfb['minor_text'].values).plot(kind='barh') #also works\n",
    "\n",
    "###this dataset only has one numeric variable\n",
    "##dfs = dfb.apply(pd.to_numeric, errors='ignore')\n",
    "##dfs.plot(x='quantity', y='survyear', kind='scatter')\n",
    "\n",
    "##dfc = dfb[(dfb.minor_text == \"BREAD WHITE SLICED STANDARD\") | (dfb.minor_text == \"BREAD WHITE SLICED PREMIUM\")]\n",
    "##pd.crosstab(dfc.survyear, dfc.minor_text, values = dfc.quantity, aggfunc=np.sum).plot(kind='line')\n",
    "##plt.title('Comparing the tendencies of 2 types of bread')\n",
    "##plt.ylabel('Survey year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Most of the 53 fields have files detailing their values:\n",
    "#=== government office region metropolitan county = 27 x (code, text)\n",
    "#df_gormet2 = pd.DataFrame.from_csv(dataRefe+'DCV_ GORMET2.txt', sep='\\t', index_col=None)\n",
    "#=== standard statistical region = 11 x (code, text); Scotland = 1\n",
    "#df_reg = pd.DataFrame.from_csv(dataRefe+'DCV_ Region.txt', sep='\\t', index_col=None)\n",
    "#=== local authority district = 457 x (code, text)\n",
    "#df_lad = pd.DataFrame.from_csv(dataRefe+'DCV_ LAD.txt', sep='\\t', index_col=None)\n",
    "#=== ownership of microwave (1 = yes 0= not)\n",
    "#df_mic = pd.DataFrame.from_csv(dataRefe+'DCV_ Microwave ownership.txt', sep='\\t', index_col=None)\n",
    "#=== ownership of freezer (1 = yes 0= not)\n",
    "#df_frez = pd.DataFrame.from_csv(dataRefe+'DCV_ Freezer ownership.txt', sep='\\t', index_col=None)\n",
    "#=== tenure (ownership of dwelling) = 7 categories\n",
    "#df_owndw = pd.DataFrame.from_csv(dataRefe+'DCV_ Ownership of dwelling.txt', sep='\\t', index_col=None)\n",
    "#=== school milk #yes, no\n",
    "#df_schmilk = pd.DataFrame.from_csv(dataRefe+'DCV_ School milk.txt', sep='\\t', index_col=None)\n",
    "#=== income group of the head of the household = 8 categories\n",
    "#df_incgp = pd.DataFrame.from_csv(dataRefe+'DCV_ Income Group.txt', sep='\\t', index_col=None)\n",
    "#=== occupation of the head of the household = 193 categories, 3 columns\n",
    "#df_occhoh = pd.DataFrame.from_csv(dataRefe+'DCV_ OCC_OCCHOH Occupation class with unpacked descriptions.txt', sep='\\t', index_col=None)\n",
    "#=== social occupation class of the head of the household = 380 categories\n",
    "#df_sochoh = pd.DataFrame.from_csv(dataRefe+'DCV_ Standard occupation class.txt', sep='\\t', index_col=None)\n",
    "#=== degree of activity of the head of the household = sedentary, active, moderate\n",
    "#df_dacthoh = pd.DataFrame.from_csv(dataRefe+'DCV_ Degree of activity.txt', sep='\\t', index_col=None)\n",
    "#=== family income type #how we know about income: net, gross, estimated\n",
    "#df_finctp = pd.DataFrame.from_csv(dataRefe+'DCV_ Family income tp.txt', sep='\\t', index_col=None)\n",
    "#=== age of head of household (banded) = 7 age groups\n",
    "#df_agehoh_banded = pd.DataFrame.from_csv(dataRefe+'Ref_Age_bands_for_household_table.txt', sep='\\t', index_col=None)\n",
    "#=== age of housewife (banded) = 7 age groups\n",
    "#df_agehw_banded = pd.DataFrame.from_csv(dataRefe+'Ref_Age_bands_for_household_table.txt', sep='\\t', index_col=None)\n",
    "#=== government office region = 13 regions (Scotland is 12)\n",
    "#df_gor = pd.DataFrame.from_csv(dataRefe+'DCV_ GOR.txt', sep='\\t', index_col=None)\n",
    "#=== age of main diary keeper = 7 age groups\n",
    "#df_agemdk_banded = pd.DataFrame.from_csv(dataRefe+'Ref_Age_bands_for_household_table.txt', sep='\\t', index_col=None)\n",
    "#=== income group (1 = All A  2=B  3=C 4=D & E2 5=E1 & OAPs)\n",
    "#df_incgpa = pd.DataFrame.from_csv(dataRefe+'DCV_ Income group (A group).txt', sep='\\t', index_col=None)\n",
    "#=== household composition = number of adults (male and female) and children\n",
    "#df_hhcomp = pd.DataFrame.from_csv(dataRefe+'DCV_ Household Composition.txt', sep='\\t', index_col=None)\n",
    "#=== household composition (all adults) = number of adults and children\n",
    "#df_hhcompa = pd.DataFrame.from_csv(dataRefe+'DCV_ Household Compositon (A group).txt', sep='\\t', index_col=None)\n",
    "#=== household composition by income group = 28 categories, how many family members are this or that\n",
    "#df_hcxigs = pd.DataFrame.from_csv(dataRefe+'DCV_ Household composition x income group.txt', sep='\\t', index_col=None)\n",
    "#=== doorstep milk delivery (1 = yes 2 = no)\n",
    "#df_doormilk = pd.DataFrame.from_csv(dataRefe+'DCV_ Doormilk.txt', sep='\\t', index_col=None)\n",
    "#=== ownership of fridge  (1 = yes 0= not)\n",
    "#df_frij = pd.DataFrame.from_csv(dataRefe+'DCV_ Fridge ownership.txt', sep='\\t', index_col=None)\n",
    "#=== occupation of crossover head of household\n",
    "#df_occxhoh = pd.DataFrame.from_csv(dataRefe+'DCV_ Occupation class.txt', sep='\\t', index_col=None)\n",
    "#=== social occupation class of cross head of household #kinds of job\n",
    "#df_socxhoh = pd.DataFrame.from_csv(dataRefe+'DCV_ Standard occupation class.txt', sep='\\t', index_col=None)\n",
    "#=== degree of activity of cross over head of household #sedentary etc\n",
    "#df_dactxhoh = pd.DataFrame.from_csv(dataRefe+'DCV_ Degree of activity.txt', sep='\\t', index_col=None)\n",
    "#===size of work establishment of head of household #sme etc\n",
    "#df_szwkest = pd.DataFrame.from_csv(dataRefe+'DCV_ Size of work establishment.txt', sep='\\t', index_col=None)\n",
    "#=== employment status of head of household (1 = employed 2 = unemployed)\n",
    "#df_empst = pd.DataFrame.from_csv(dataRefe+'DCV_ Employment status.txt', sep='\\t', index_col=None)\n",
    "#=== weekday (1 st day of recording) 1 = Sunday....7=Saturday\n",
    "#df_wkdy1rec = pd.DataFrame.from_csv(dataRefe+'DCV_ Weekday (1st day of recording).txt', sep='\\t', index_col=None)\n",
    "#=== vegetarian indicator\n",
    "#df_vegind = pd.DataFrame.from_csv(dataRefe+'DCV_ Vegetarian indicator.txt', sep='\\t', index_col=None)\n",
    "#=== government office region for northwest and merseyside (1=north west/merseyside 2=other)\n",
    "#df_gornw = pd.DataFrame.from_csv(dataRefe+'DCV_ GORNW.txt', sep='\\t', index_col=None) #FILE DOES NOT EXIST\n",
    "#=== job status of head of household\n",
    "#df_jobsthoh = pd.DataFrame.from_csv(dataRefe+'DCV_ Job status of HOH.txt', sep='\\t', index_col=None)\n",
    "#=== income group (1974-1975)\n",
    "#df_incgp745 = pd.DataFrame.from_csv(dataRefe+'DCV_ Income group 7475.txt', sep='\\t', index_col=None)\n",
    "#=== with job indicator - accomodation tied to employment\n",
    "#df_withjob = pd.DataFrame.from_csv(dataRefe+'DCV_ WITHJOB (1998 to 2000 only).txt', sep='\\t', index_col=None)\n",
    "#=== landlord status indicator: type of landlord\n",
    "#df_landlord = pd.DataFrame.from_csv(dataRefe+'DCV_ LANDLORD (1998 to 2000 only).txt', sep='\\t', index_col=None)\n",
    "#=== furnished indicator: is the accomodation furnished #FILE DOES NOT EXIST\n",
    "#df_furnish = pd.DataFrame.from_csv(dataRefe+'DCV_ FURNISHED (1998 to 2000 only).txt', sep='\\t', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===== LOOK AT UNITS IN \"BAD GROUPS\" and \"GOOD GROUPS\"\n",
    "\n",
    "df = df_groups\n",
    "df = pd.merge(df, df_min_units, how='left', on='minor')\n",
    "\n",
    "print \"BAD GROUPS:\"\n",
    "for g in bad_groups:\n",
    "    this_group = g\n",
    "    dfg = df[df.group_text == this_group]\n",
    "    list_of_units = dfg['units'].tolist()\n",
    "    first_unit = list_of_units[0]\n",
    "    all_units_are_the_same = \"yes\"\n",
    "    for u in list_of_units:\n",
    "            this_unit = u\n",
    "            if this_unit != first_unit: all_units_are_the_same = \"no\"\n",
    "    if all_units_are_the_same == \"no\":\n",
    "        print this_group, \"have different units:\", list_of_units\n",
    "        #print dfg.minor_text.unique()\n",
    "        #print dfg[['minor_text', 'units']]\n",
    "    else:\n",
    "        print this_group, \"are all\", this_unit\n",
    "        #print dfg.minor_text.unique()\n",
    "        \n",
    "\n",
    "df = df_groups\n",
    "df = pd.merge(df, df_min_units, how='left', on='minor')\n",
    "\n",
    "print good_groups\n",
    "print \"GOOD GROUPS:\"\n",
    "for g in good_groups:\n",
    "    this_group = g\n",
    "    dfg = df[df.group_text == this_group]\n",
    "    list_of_units = dfg['units'].tolist()\n",
    "    first_unit = list_of_units[0]\n",
    "    all_units_are_the_same = \"yes\"\n",
    "    for u in list_of_units:\n",
    "            this_unit = u\n",
    "            if this_unit != first_unit: all_units_are_the_same = \"no\"\n",
    "    if all_units_are_the_same == \"no\":\n",
    "        print this_group, \"have different units:\", list_of_units\n",
    "        #print dfg.minor_text.unique()\n",
    "        #print dfg[['minor_text', 'units']]\n",
    "    else:\n",
    "        print this_group, \"are all\", this_unit\n",
    "        #print dfg.minor_text.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We have the 47 nutrients (txt from a PDF)\n",
    "df_nut_names = pd.DataFrame.from_csv(dataRefe+'Nutrient Conversion factors.txt', sep=',', index_col=None)\n",
    "df_nut_names.columns=['nutrient','nutr_text', 'nutr_comments']\n",
    "df_nut_names.head(8) # we're interested in nutrient = 8 (Energy - Kcal)\n",
    "#We have the conversion factors for each 315 'minor', for each of the 4 quarters of year 2000\n",
    "df_nut2000 = pd.DataFrame.from_csv(data2000+'2000 nutrient conversion factors.txt', sep='\\t', index_col=None)\n",
    "df_nut2000.columns=['minor', 'nutrient', 'year', 'quarter', 'nutconvfactor']\n",
    "#We merge the nutrients with the conversion factors\n",
    "df_nut = pd.merge(df_nut2000, df_nut_names, how='left', on='nutrient')\n",
    "df_nut = pd.merge(df_nut, df_min_maj, how='left', on='minor')\n",
    "df_nut.drop(['major'], inplace=True, axis=1) #to avoid duplicate later\n",
    "#.shape #(43348, 8) (some of the 'minor' had no nutrients)\n",
    "#'minor', 'nutrient', 'year', 'quarter', 'nutconvfactor', 'nutr_text', 'nutr_comments', 'minor_text'\n",
    "print \"Notice how the NCV is different for each quarter (of 2000), so later we'll have to average them\"\n",
    "df_nut[['minor_text', 'nutr_text', 'quarter', 'nutconvfactor']].head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_nut[df_nut.nutrient == 8] #Select nutrient = Calories\n",
    "df = df.pivot(index='minor', columns='quarter', values='nutconvfactor')\n",
    "df.columns.name = None\n",
    "df.columns = ['q1', 'q2', 'q3', 'q4']\n",
    "df['calories'] = (df.q1 + df.q2 + df.q3 + df.q4) / 4 #average all the calories for the 4 quarters of 2000\n",
    "df_min_cal = df\n",
    "df_min_cal.head(3) #307, not 315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read foods\n",
    "df_min_maj = pd.DataFrame.from_csv(dataRefe+'Ref_ Minor and major foods.txt', sep='\\t', index_col=None)\n",
    "df_min_maj.columns=['minor', 'minor_text', 'major']\n",
    "df_food = df_min_maj\n",
    "df_food.index = df_food['minor']\n",
    "#read calories for each food\n",
    "df_min_cal.index = df_min_cal['minor']\n",
    "df_cal = df_min_cal[['minor', 'calories']]\n",
    "#merge\n",
    "df_food_cal = pd.merge(df_food, df_cal, how='left', on='minor')\n",
    "df_food.head(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df3, df_diary, how='left', on='minor')\n",
    "df[['minor', 'quantity', 'calories']].head(5)\n",
    "df_cal_consumed = df\n",
    "df_cal_consumed['calconsumed'] = df_cal_consumed.quantity * df_cal_consumed.calories\n",
    "df_cal_consumed[['minor', 'quantity', 'calories', 'calconsumed']].head(5)\n",
    "df_cal_consumed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_cal_consumed has the calories consumed in detail: by hh and by fooditem\n",
    "#i'd like to sum that up into df_cal_household, with all the calories consumed by each family\n",
    "#currently i have no idea how to do that ... groupby then aggregate ?????\n",
    "\n",
    "import numpy as np\n",
    "df_cal_household = df_cal_consumed.groupby('hhno')\n",
    "print len(df_cal_consumed)\n",
    "print len(df_cal_household)\n",
    "df_cal_household.aggregate(np.sum) # DOESN'T WORK !!! TIME FOR A REST !!!\n",
    "#df_cal_household.groupby('calories', as_index=False).sum()\n",
    "\n",
    "sum_cal = df_cal_consumed.groupby('hhno')['calories'].sum()\n",
    "sum_cal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cal_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now i only have to join them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "c0=sns.color_palette()[0]\n",
    "c1=sns.color_palette()[1]\n",
    "c2=sns.color_palette()[2]\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "def points_plot(ax, Xtr, Xte, ytr, yte, clf, mesh=True, colorscale=cmap_light, cdiscrete=cmap_bold, \\\n",
    "                alpha=0.1, psize=10, zfunc=False, predicted=False):\n",
    "    h = .02\n",
    "    X=np.concatenate((Xtr, Xte))\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    #plt.figure(figsize=(10,6))\n",
    "    if zfunc:\n",
    "        p0 = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 0]\n",
    "        p1 = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        Z=zfunc(p0, p1)\n",
    "    else:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    ZZ = Z.reshape(xx.shape)\n",
    "    if mesh:\n",
    "        plt.pcolormesh(xx, yy, ZZ, cmap=cmap_light, alpha=alpha, axes=ax)\n",
    "    if predicted:\n",
    "        showtr = clf.predict(Xtr)\n",
    "        showte = clf.predict(Xte)\n",
    "    else:\n",
    "        showtr = ytr\n",
    "        showte = yte\n",
    "    ax.scatter(Xtr[:, 0], Xtr[:, 1], c=showtr-1, cmap=cmap_bold, s=psize, alpha=alpha,edgecolor=\"k\")\n",
    "    # and testing points\n",
    "    ax.scatter(Xte[:, 0], Xte[:, 1], c=showte-1, cmap=cmap_bold, alpha=alpha, marker=\"s\", s=psize+10)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    return ax,xx,yy\n",
    "\n",
    "def points_plot_prob(ax, Xtr, Xte, ytr, yte, clf, colorscale=cmap_light, cdiscrete=cmap_bold, \\\n",
    "                     ccolor=cm, psize=10, alpha=0.1):\n",
    "    ax,xx,yy = points_plot(ax, Xtr, Xte, ytr, yte, clf, mesh=False, colorscale=colorscale, \\\n",
    "                           cdiscrete=cdiscrete, psize=psize, alpha=alpha, predicted=True) \n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=ccolor, alpha=.2, axes=ax)\n",
    "    cs2 = plt.contour(xx, yy, Z, cmap=ccolor, alpha=.6, axes=ax)\n",
    "    plt.clabel(cs2, fmt = '%2.1f', colors = 'k', fontsize=14, axes=ax)\n",
    "    return ax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=5):\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(Xtrain, ytrain)\n",
    "    print \"BEST PARAMS\", gs.best_params_\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, standardize=False, train_size=0.8):\n",
    "    subdf=indf[featurenames]\n",
    "    if standardize:\n",
    "        subdfstd=(subdf - subdf.mean())/subdf.std()\n",
    "    else:\n",
    "        subdfstd=subdf\n",
    "    X=subdfstd.values\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size)\n",
    "    clf = cv_optimize(clf, parameters, Xtrain, ytrain)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = df[df.good_cart == 1].plot.scatter(x='reg', y='child', color='DarkOrange', label='Good');\n",
    "df[df.good_cart == 0].plot.scatter(x='reg', y='child', color='Grey', label='Bad', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It looks like I'll have to use\n",
    "# http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html\n",
    "# sklearn.preprocessing.scale(X, axis=0, with_mean=True, with_std=True, copy=True)[source]\n",
    "# I guess the matrix would be the 24 groups x 45k observations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
